{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lZa4YoWAYvM-"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "------------------------------ Pivot Table ------------------------------\n",
        "\n",
        "The below code enables the creation of a certain form of\n",
        "'pivot' table through the function PivotTable(). It returns\n",
        "a pandas.DataFrame() object with rows being the unique values\n",
        "of the 'key' column provided and the columns specified in\n",
        "'structs', which are to be passed in as arguemnts to the\n",
        "PivotTable() function.\n",
        "\n",
        "Function:-\n",
        "\n",
        "PivotTable(data, key, *structs)\n",
        "\n",
        "data - expects a pandas.DataFrame object of the original data\n",
        "key - expects a string name of the column you want to insepct\n",
        "structs - expects a one or multiple list objects containing two\n",
        "          things: the string name of the column, and the operation\n",
        "          you want to see being applied on that column. The\n",
        "          options for different operations is given below.\n",
        "\n",
        "NOTE: Only the 'mode' operation should be used if the struct column\n",
        "      has non-numerical values.\n",
        "\n",
        "Operations :-\n",
        "\n",
        "'avg': provides the average of the column (excludes any NaN values)\n",
        "'sum': provides the total sum of the column (excludes any NaN values)\n",
        "'Count': provides the total number of data points.\n",
        "'binCount': simply subtracts the sum from the len, useful if the\n",
        "            data is binary\n",
        "'std': provides the standard deviation of the column\n",
        "'mode': provides the mode of the column\n",
        "'median': provides the median of the column\n",
        "'rmode': provides the least occuring item in the column\n",
        "'max': provides the maximum valued item in the column\n",
        "'min': provides the minimum valued item in the column\n",
        "\n",
        "Example usage :-\n",
        "\n",
        "Df = PivotTable(data, 'loan_status', ['grades', 'mode'], ['annual_inc', 'avg'])\n",
        "print(Df)\n",
        "\n",
        "----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import re\n",
        "import numpy\n",
        "import pandas\n",
        "import warnings\n",
        "from collections import Counter\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import pointbiserialr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def are_all_nums_or_floats(lst):\n",
        "    return all(isinstance(x, (int, float)) for x in lst)\n",
        "\n",
        "def is_duplicate (col) :\n",
        "  col = col.to_numpy()\n",
        "  return (col[0] == col).all()\n",
        "\n",
        "def get_unique (frame, col) :\n",
        "  cols = frame[col].unique()\n",
        "  print(f'Length: {len(cols)}')\n",
        "  for i in cols :\n",
        "    print(i)\n",
        "\n",
        "def drop_column (dropped, data, col) :\n",
        "  if type(col) == type(list()):\n",
        "    for i in col :\n",
        "      dropped[i] = data.pop(i)\n",
        "    return\n",
        "  else:\n",
        "    dropped[col] = data.pop(col)\n",
        "\n",
        "def clean_year(year):\n",
        "  if type(year) != type(\"\") :\n",
        "    return None\n",
        "  if \"10+\" in year :\n",
        "    return float(re.sub(r'(\\d+)\\s*\\+\\s*years', r'\\1', year))\n",
        "  if \"<\" in year :\n",
        "    return float(re.sub(r'<\\s*1\\s*years*', '0.5', year))\n",
        "  else :\n",
        "    return float(re.sub(r'\\s*years*$', '', year))\n",
        "\n",
        "def Operations (nlist, operation=None) :\n",
        "  if operation == 'avg' and are_all_nums_or_floats(nlist):\n",
        "    return numpy.nanmean(numpy.array(nlist))\n",
        "  if operation == 'sum' and are_all_nums_or_floats(nlist):\n",
        "    return numpy.nansum(numpy.array(nlist))\n",
        "  if operation == 'Count':\n",
        "    return len(nlist)\n",
        "  if operation == 'binCount' and are_all_nums_or_floats(nlist):\n",
        "    return len(nlist) - sum(nlist)\n",
        "  if operation == 'mode':\n",
        "    counts = Counter(nlist)\n",
        "    return max(counts, key=counts.get)\n",
        "  if operation == 'rmode':\n",
        "    counts = Counter(nlist)\n",
        "    return min(counts, key=counts.get)\n",
        "  if operation == 'median' and are_all_nums_or_floats(nlist):\n",
        "    return numpy.median(numpy.array(nlist))\n",
        "  if operation == 'std' and are_all_nums_or_floats(nlist):\n",
        "    return numpy.std(numpy.array(nlist))\n",
        "  if operation == 'max' and are_all_nums_or_floats(nlist):\n",
        "    return numpy.max(numpy.array(nlist))\n",
        "  if operation == 'min' and are_all_nums_or_floats(nlist):\n",
        "    return numpy.min(numpy.array(nlist))\n",
        "  if operation is None:\n",
        "    return nlist\n",
        "\n",
        "class Map :\n",
        "\n",
        "  def __init__(self, data, key) :\n",
        "    self.data = data\n",
        "    self.keys = list(data[key])\n",
        "\n",
        "  def operationCol (self, value, operations) :\n",
        "    self.map, self.freq = dict(), dict()\n",
        "    values = list(self.data[value])\n",
        "    for i in range(len(self.keys)) :\n",
        "      if self.keys[i] not in self.map.keys () :\n",
        "        self.freq[self.keys[i]] = 1\n",
        "        self.map[self.keys[i]] = [values[i]]\n",
        "      else :\n",
        "        self.freq[self.keys[i]] += 1\n",
        "        self.map[self.keys[i]].append(values[i])\n",
        "    for i in self.map.keys() :\n",
        "      self.map[i] = Operations(self.map[i], operation=operations)\n",
        "    return list(self.map.values())\n",
        "\n",
        "def PivotTable (data, key, *structs) :\n",
        "  if structs == [] or key == '':\n",
        "    print('Empty List!', end=\" \")\n",
        "    return\n",
        "  else :\n",
        "    map = Map (data, key)\n",
        "    df = pandas.DataFrame()\n",
        "    for col in structs :\n",
        "      df[f\"{col[0]}({col[1]})\"] = map.operationCol(col[0], col[1])\n",
        "    df.index = map.map.keys()\n",
        "    df.insert(0, 'Freq', map.freq.values())\n",
        "    return df\n",
        "\n",
        "\"\"\"\n",
        "------------------------------- Default Rate -------------------------------\n",
        "\n",
        "The default rate is a derived metric, essentially calculated by taking the\n",
        "number of people who have defaulted in that particular row, and dividing it\n",
        "by the total number of people who've taken the loan in that category.\n",
        "\n",
        "----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "def DefaultRate (data, key) :\n",
        "  df = PivotTable (data, key, ['loan_status', 'binCount'], ['annual_inc', 'median'])\n",
        "  df['DefaultRate(%)'] = (df['loan_status(binCount)'] / df['Freq']) * 100\n",
        "  print(df)\n",
        "  if key == 'income_bracket' or key == 'grade' or key == 'sub_grade':\n",
        "    print(f\"Skewness: {skew(df['DefaultRate(%)'], bias=False)}\")\n",
        "  print()\n",
        "  fig = plt.figure(figsize=(10, 6), facecolor='#364449', edgecolor='white')\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.set_facecolor('#364449')\n",
        "  bars = plt.bar(df.index, df['DefaultRate(%)'], color='skyblue')\n",
        "  for bar in bars:\n",
        "    bar.set_color('white')  # Bar color\n",
        "  plt.xticks(color='white')  # X-axis tick color\n",
        "  plt.yticks(color='white')  # Y-axis tick color\n",
        "  plt.xlabel(key, color='white')  # X-axis label color\n",
        "  plt.ylabel('Default Rate in %', color='white')  # Y-axis label color\n",
        "  plt.title('Defaults', color='white')  # Plot title color\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "leNtljfBOIdS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pandas.read_csv('loan.csv')\n",
        "columns = list(data.columns)\n",
        "dropped_columns = pandas.DataFrame()\n",
        "\n",
        "\"\"\"\n",
        "----------------------------- Data Engineering -----------------------------\n",
        "\n",
        "The following modifications where made :\n",
        " > Removal of columns with over 25000 NULL values or with too many duplicate\n",
        "   values.\n",
        " > Removal of columns with too many unique values, where proper analysis is not\n",
        "   possible, there being too much noise.\n",
        " > Removing people who have neither paid nor defaulted ('Current' in their status).\n",
        " > Changing the data type of 'emp_length' to numerical years, where '<1 years'\n",
        "   is taken to be as 0.5, while '10+ years' is simply 10.\n",
        " > The column, 'term', is also converted to binary: 0 for 36 months and 1 for 60.\n",
        " > 'loan_status' is also converted to binary: 0 for 'Charged Off' and 1 for\n",
        "   'Fully paid'.\n",
        " > 'verification_status' is also converted to binary: 0 for 'Not Verified' and 1\n",
        "   otherwise.\n",
        " > The 'annual_inc' column was used to create a new column of income brackets,\n",
        "   where incomes where grouped together like so:\n",
        "   (['0-60000', '60000-120000', '120000-240000', '>240000'])\n",
        "\n",
        "----------------------------------------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "## Removing columns with too many NULL values\n",
        "for i in range(len(columns)) :\n",
        "  if data[columns[i]].isna().sum() > 25000 or is_duplicate(data[columns[i]]):\n",
        "    drop_column(dropped_columns, data, columns[i])\n",
        "\n",
        "## Removing unwanted columns\n",
        "drop_column(dropped_columns, data, ['id', 'member_id', 'emp_title', 'url', 'desc', 'title', 'zip_code'])\n",
        "\n",
        "## Splitting up annual income into income-brackets\n",
        "bins = [0, 60000, 120000, 240000, float('inf')]\n",
        "labels = ['0-60000', '60000-120000', '120000-240000', '>240000']\n",
        "\n",
        "## Data engineering\n",
        "data = data[data['loan_status'] != 'Current']\n",
        "data['int_rate'] = [float(i.replace(\"%\",\"\")) for i in data['int_rate']]\n",
        "data['emp_length'] = [clean_year(i) for i in data['emp_length']]\n",
        "data['loan_status'] = [0 if i == 'Charged Off' else 1 for i in data['loan_status']]\n",
        "data['term'] = [0 if i == ' 36 months' else 1 for i in data['term']]\n",
        "data['verification_status'] = [0 if i == 'Not Verified' else 1 for i in data['verification_status']]\n",
        "data['income_bracket'] = pandas.cut(data['annual_inc'], bins=bins, labels=labels, right=False)"
      ],
      "metadata": {
        "id": "3ryO6PpJqIKA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyVariable = 'loan_status'\n",
        "valueVariables = [\n",
        "    ['funded_amnt', 'sum'],\n",
        "    ['funded_amnt_inv', 'sum'],\n",
        "    ['term', 'binCount'],\n",
        "    ['int_rate', 'avg'],\n",
        "    ['installment', 'avg'],\n",
        "    ['grade', 'mode'],\n",
        "    ['sub_grade', 'mode'],\n",
        "    ['emp_length', 'avg'],\n",
        "    ['home_ownership', 'mode'],\n",
        "    ['annual_inc', 'median'],\n",
        "    ['purpose', 'mode'],\n",
        "    ['pub_rec_bankruptcies', 'sum'],\n",
        "    ['pub_rec', 'sum'],\n",
        "    ['dti', 'avg'],\n",
        "    ['open_acc', 'max'],\n",
        "    ['addr_state', 'mode']\n",
        "]\n",
        "\n",
        "Df = PivotTable (data, keyVariable, *valueVariables)\n",
        "Df.insert(3, 'investors(%)', Df['funded_amnt_inv(sum)']/Df['funded_amnt(sum)'])\n",
        "Df['Bankruptcy(%)'] = Df['pub_rec_bankruptcies(sum)'] / Df['Freq'] * 100\n",
        "Df['Derogatory_Records(%)'] = Df['pub_rec(sum)'] / Df['Freq'] * 100\n",
        "print(Df)"
      ],
      "metadata": {
        "id": "kguWyYLjo9Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = PivotTable(data, 'loan_status', ['total_pymnt', 'avg'], ['funded_amnt', 'avg'])\n",
        "df['remaining_amnt'] = (df['funded_amnt(avg)'] - df['total_pymnt(avg)']).apply(lambda x: max(0, x))\n",
        "df['remaining(%)'] = (df['remaining_amnt'] / df['funded_amnt(avg)']) * 100\n",
        "print(df)"
      ],
      "metadata": {
        "id": "BRKvl3FEys4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DefaultRate(data, 'home_ownership')"
      ],
      "metadata": {
        "id": "1Or8-9AO_tsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DefaultRate(data, 'income_bracket')"
      ],
      "metadata": {
        "id": "OKPYNXQKClyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DefaultRate(data, 'purpose')"
      ],
      "metadata": {
        "id": "HTB_4_7KCl99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DefaultRate(data, 'addr_state')"
      ],
      "metadata": {
        "id": "D2rQgugPCmGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DefaultRate(data, 'grade')"
      ],
      "metadata": {
        "id": "rXDVXNkeCmOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DefaultRate(data, 'sub_grade')"
      ],
      "metadata": {
        "id": "2DxhS8UZCroL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newData = data[data['pub_rec_bankruptcies'].notna()]\n",
        "df = PivotTable(newData, 'pub_rec_bankruptcies', ['int_rate', 'avg'])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "S7h4sSkBl7Bs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
